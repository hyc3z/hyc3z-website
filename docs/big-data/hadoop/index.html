<!doctype html>
<html class="docs-version-current" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.15">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Hyc的踩坑之旅 RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Hyc的踩坑之旅 Atom Feed"><title data-react-helmet="true">hadoop | Hyc的踩坑之旅</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://hyc3z.github.io/docs/big-data/hadoop"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="hadoop | Hyc的踩坑之旅"><meta data-react-helmet="true" name="description" content="Hadoop"><meta data-react-helmet="true" property="og:description" content="Hadoop"><link data-react-helmet="true" rel="icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://hyc3z.github.io/docs/big-data/hadoop"><link data-react-helmet="true" rel="alternate" href="https://hyc3z.github.io/docs/big-data/hadoop" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://hyc3z.github.io/docs/big-data/hadoop" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.366311be.css">
<link rel="preload" href="/assets/js/runtime~main.8c487385.js" as="script">
<link rel="preload" href="/assets/js/main.036a9873.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title">Hyc3z</b></a><a class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Notes</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_Pssr toggle_TdHA toggleDisabled_jDku"><div class="toggleTrack_SSoT" role="button" tabindex="-1"><div class="toggleTrackCheck_XobZ"><span class="toggleIcon_eZtF">🌜</span></div><div class="toggleTrackX_YkSC"><span class="toggleIcon_eZtF">🌞</span></div><div class="toggleTrackThumb_uRm4"></div></div><input type="checkbox" class="toggleScreenReader_JnkT" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_P2Lg"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_RiI4" type="button"></button><aside class="theme-doc-sidebar-container docSidebarContainer_rKC_"><div class="sidebar_CW9Y"><nav class="menu thin-scrollbar menu_SkdO"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">intro</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_VCh3" href="/docs/ai/deep_learning">ai</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active hasHref_VCh3" aria-current="page" href="/docs/big-data/hadoop">big-data</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/big-data/hadoop">hadoop</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/big-data/kafka">kafka</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_VCh3" href="/docs/blockchain/Chainlink">blockchain</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_VCh3" href="/docs/cpp/pcal">cpp</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_VCh3" href="/docs/cryptography/overview">cryptography</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_VCh3" href="/docs/database/Oracle">database</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_VCh3" href="/docs/design/microservices">design</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link hasHref_VCh3" href="/docs/git/">git</a><button aria-label="Toggle the collapsible sidebar category &#x27;git&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_VCh3" href="/docs/graph/graph-database">graph</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_VCh3" href="/docs/python/re">python</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_VCh3" href="/docs/ts/typescript">ts</a></div></li></ul></nav></div></aside><main class="docMainContainer_TCnq"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_DM6M"><div class="docItemContainer_vinB"><article><div class="tocCollapsible_jdIR theme-doc-toc-mobile tocMobile_TmEX"><button type="button" class="clean-btn tocCollapsibleButton_Fzxq">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>hadoop</h1></header><h3 class="anchor anchorWithStickyNavbar_mojV" id="hadoop">Hadoop<a class="hash-link" href="#hadoop" title="Direct link to heading">​</a></h3><p><img alt="MapReduce logical data flow" src="/assets/images/hddg_0201-565ba1dd61ad20c95ff4303ba0bb72c2.png" width="1000" height="192"></p><p>数据处理分为两个阶段：Map和Reduce</p><p>Map阶段会对数据进行清洗，过滤以及解析。</p><p>然后经过mapreduce进行加工，再传给reduce function</p><p>最后得到结果</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="mapreduce-job">MapReduce Job<a class="hash-link" href="#mapreduce-job" title="Direct link to heading">​</a></h4><p>一个Job 包含输入数据，配置，以及MapReduce Program</p><p>Hadoop负责把job拆分成一系列Tasks，这些task只有两种类型：Map和Reduce</p><p>这些task被YARN调度，在节点上运行。如果Task失败了，它会自动被安排在另一个节点上运行。</p><p>（注：这个Yarn和nodejs的yarn容易发生命令行冲突，因此也可以用yarnpkg来调用）</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="splits">Splits<a class="hash-link" href="#splits" title="Direct link to heading">​</a></h5><p>Hadoop会把数据纵向拆开，分给不同的task去做map，这样可以提升效率。</p><p>对大多数Job来说，Split size就是HDFS Block的大小，128MB</p><p>如果大于128MB，就有可能会出现结果存在多个Block中，可能会存在多个节点里，出现网络请求。</p><p>Map Task的结果是写在本地磁盘，不是写在HDFS里的，因为它属于中间结果</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="data-flow">Data Flow<a class="hash-link" href="#data-flow" title="Direct link to heading">​</a></h5><p><img alt="MapReduce data flow with a single reduce task" src="/assets/images/hddg_0203-6dd0644d38d83417bc59a7ea255a0740.png" width="1000" height="538"></p><p>虚线代表本地数据流，实线代表跨Node数据流。</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="multiple-tasksshuffle">Multiple Tasks(shuffle)<a class="hash-link" href="#multiple-tasksshuffle" title="Direct link to heading">​</a></h5><p><img alt="MapReduce data flow with multiple reduce tasks" src="/assets/images/hddg_0204-b106253fc8c15aca49c21bd56355a8b4.png" width="1000" height="538"></p><h5 class="anchor anchorWithStickyNavbar_mojV" id="combiner-function">Combiner function<a class="hash-link" href="#combiner-function" title="Direct link to heading">​</a></h5><p>除了Mapper和Reducer，还可以根据实际情况选择Combiner 来减少数据的交换。</p><p>比如求最大值，就可以用Combiner，在每个Map结束后直接调用，最后的结果不变，但参与网络交换的数据大大减少了。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">max(0, 20, 10, 25, 15) = max(max(0, 20, 10), max(25, 15)) = max(20, 25) = 25</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>当然，不是所有问题都能够用得到。</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="hadoop-streaming">Hadoop Streaming<a class="hash-link" href="#hadoop-streaming" title="Direct link to heading">​</a></h5><p>理论上，只要是能够读取/写入 Unix标准IO的都能够使用Hadoop Streaming，所以不一定要用Java。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="hadoop-distributed-filesystem-hdfs">Hadoop Distributed Filesystem (HDFS)<a class="hash-link" href="#hadoop-distributed-filesystem-hdfs" title="Direct link to heading">​</a></h3><p>Hadoop其实也可以和其他文件系统结合，比如Amazon S3或者本地文件系统。</p><p>HDFS的<strong>特点</strong>：</p><p>支持超大文件、民用硬件、流式文件存取</p><p>HDFS的<strong>缺点</strong>：</p><p>延迟（挖坑 HBase）、大量小文件</p><p>Append-only，不支持随机写入，不支持Multi writer</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="blocks">Blocks<a class="hash-link" href="#blocks" title="Direct link to heading">​</a></h5><p>HDFS的文件都被Chunk成Block进行存储，每个Block 128MB。当然，不像磁盘的4K 块大小，小于128M的文件在HDFS里并不会占有128MB，而是文件原来的大小。</p><p>之所以HDFS的块那么大，就是为了最小化seek time，也就是寻找块的时间。</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="namenodes-and-datanodes">Namenodes and Datanodes<a class="hash-link" href="#namenodes-and-datanodes" title="Direct link to heading">​</a></h5><p>Namenode: master</p><p>负责管理文件系统的namespace，filesystem tree，metadata，directories。</p><p>存储在本地，namespace image和edit log</p><p>并且，在系统启动时，还会通过datanode建立一个文件块和datanode的位置映射，但是是非持久化的。</p><p>Namenode如果挂了，数据就全丢失了。因为没有办法知道如何从块重建文件。</p><p>第一种办法，就是备份Namenode的state，写到本地磁盘或者nfs。</p><p>第二种办法，就是另外运行一个node来定时merge namespace image和edit log。</p><p>Datanode: workers</p><p>存取块，接受namenode或者client的请求。</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="block-caching">Block Caching<a class="hash-link" href="#block-caching" title="Direct link to heading">​</a></h5><p>指定一些经常使用的Block，放入内存中作为Cache</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="memory">Memory<a class="hash-link" href="#memory" title="Direct link to heading">​</a></h5><p>1,000 MB per million blocks of storage</p><p>a 200-node cluster with 24 TB of disk space per node, a block size of 128 MB, and a replication factor of 3</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">&gt;&gt;&gt; 200* 24000000 / 128 / 3 / 1000000 * 1000</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">12500.0</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h5 class="anchor anchorWithStickyNavbar_mojV" id="federation">Federation<a class="hash-link" href="#federation" title="Direct link to heading">​</a></h5><p>HDFS Federation, 2.x版本开始, 多个Namenode分别管理集群中的一部分</p><p>比如Node 0管理/user，Node 1 管理/share</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="hdfs-ha">HDFS HA<a class="hash-link" href="#hdfs-ha" title="Direct link to heading">​</a></h5><p>NFS或者QJM，来让一对热备的Namenode能够同时访问到edit log，然后能够接管</p><p>QJM就是一个小型的HDFS，提供高可用edit log</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="failover">Failover<a class="hash-link" href="#failover" title="Direct link to heading">​</a></h5><p>ZooKeeper确定只有一个Namenode是活动的</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="fencing">Fencing<a class="hash-link" href="#fencing" title="Direct link to heading">​</a></h5><p>假设原有的Node依然在运行，但由于网络原因被认为失效了，触发了Failover，需要一些机制来确保这个Node不造成太多的伤害。这个过程被称为Fencing</p><p>QJM只允许同时有一个Namenode写edit log，但是NFS没办法做到</p><p><em>STONITH</em>, or “shoot the other node in the head,” </p><p>直接控制电源让另一个host关机</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="简单命令">简单命令<a class="hash-link" href="#简单命令" title="Direct link to heading">​</a></h4><p>From Local</p><p><code>hadoop fs -copyFromLocal input/docs/quangle.txt /user/tom/quangle.txt</code></p><p>To Local</p><p><code>hadoop fs -copyToLocal quangle.txt quangle.copy.txt</code></p><h4 class="anchor anchorWithStickyNavbar_mojV" id="data-flow-1">Data Flow<a class="hash-link" href="#data-flow-1" title="Direct link to heading">​</a></h4><h5 class="anchor anchorWithStickyNavbar_mojV" id="client-access-mode">Client Access Mode<a class="hash-link" href="#client-access-mode" title="Direct link to heading">​</a></h5><p><img alt="Accessing HDFS over HTTP directly and via a bank of HDFS proxies" src="/assets/images/hddg_0301-82db54098077811ac4a9b3e42a3b4f8b.png" width="984" height="1000"></p><h5 class="anchor anchorWithStickyNavbar_mojV" id="file-write">File Write<a class="hash-link" href="#file-write" title="Direct link to heading">​</a></h5><p><img alt="A client writing data to HDFS" src="/assets/images/hddg_0304-b3d309abf2a2450c2c4d5c0e1917580c.png" width="1000" height="687"></p><p>NameNode会先去check 文件是否存在，是否有权限等。如果check通过了，会增加一条new file的record。</p><p><code>dfs.namenode.replication.min</code> replicas (which defaults to 1) are written, 就会success</p><p>asynchronously replicated across the cluster, <code>dfs.replication</code>, which defaults to 3</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="file-read">File Read<a class="hash-link" href="#file-read" title="Direct link to heading">​</a></h5><p><img alt="A client reading data from HDFS" src="/assets/images/hddg_0302-c8cb8291ea25d076380dab6ecd22d5f1.png" width="1000" height="602"></p><h5 class="anchor anchorWithStickyNavbar_mojV" id="distances">Distances<a class="hash-link" href="#distances" title="Direct link to heading">​</a></h5><ul><li><em>distance(/d1/r1/n1, /d1/r1/n1)</em> = 0 (processes on the same node)</li><li><em>distance(/d1/r1/n1, /d1/r1/n2)</em> = 2 (different nodes on the same rack)</li><li><em>distance(/d1/r1/n1, /d1/r2/n3)</em> = 4 (nodes on different racks in the same data center)</li><li><em>distance(/d1/r1/n1, /d2/r3/n4)</em> = 6 (nodes in different data centers)</li></ul><h5 class="anchor anchorWithStickyNavbar_mojV" id="replica-strategy">Replica Strategy<a class="hash-link" href="#replica-strategy" title="Direct link to heading">​</a></h5><p><img alt="A typical replica pipeline" src="/assets/images/hddg_0305-dd6b7f3ffae9cc0ec406e8ab622da51c.png" width="699" height="772"></p><p>同Node，Node On other rack, other node on that rack</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="flush">Flush<a class="hash-link" href="#flush" title="Direct link to heading">​</a></h5><p>正在写的Block，很可能还是读取不了的状态，需要达到一个Block的大小后缓存才会被Flush。当然也有API可以Force Flush</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="parallel-copying">Parallel Copying<a class="hash-link" href="#parallel-copying" title="Direct link to heading">​</a></h5><p><code> hadoop distcp file1 file2</code></p><p>distcp本身是一个MapReduce Job，每个file都被一个map copy。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="yarn-yet-another-resource-negotiator">YARN (Yet Another Resource Negotiator)<a class="hash-link" href="#yarn-yet-another-resource-negotiator" title="Direct link to heading">​</a></h3><p>Yarn 是Hadoop的集群资源管理系统。</p><p><img alt="YARN applications" src="/assets/images/hddg_0401-505d71e442efe4ce248f91816823d9a9.png" width="1000" height="361"></p><p>提供一个API来访问集群的资源，通常是被更高级的API调用的。</p><p><img alt="How YARN runs an application" src="/assets/images/hddg_0402-675ca1e354d72d1ce4f647d35db97ca4.png" width="1000" height="985"></p><p>这个Container可以是Unix Process，也可以是Linux的cgroup</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="resource-requests">Resource Requests<a class="hash-link" href="#resource-requests" title="Direct link to heading">​</a></h5><p>Yarn Application可以在运行前就申请好所有资源，或者在运行时动态地申请更多的资源。</p><p>Spark就是使用的前一种方式</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="application-lifespan">Application Lifespan<a class="hash-link" href="#application-lifespan" title="Direct link to heading">​</a></h5><p>App per job</p><p>App per workflow/session of jobs</p><p>Long-running</p><p>Spark采用的第二种</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="mapreduce-1-and-yarn">Mapreduce 1 and Yarn<a class="hash-link" href="#mapreduce-1-and-yarn" title="Direct link to heading">​</a></h5><table><thead><tr><th>MapReduce 1</th><th>YARN</th></tr></thead><tbody><tr><td>Jobtracker</td><td>Resource manager, application master, timeline server</td></tr><tr><td>Tasktracker</td><td>Node manager</td></tr><tr><td>Slot</td><td>Container</td></tr><tr><td>4000 nodes and 40000 tasks</td><td>10000 nodes and 100000 tasks</td></tr></tbody></table><h5 class="anchor anchorWithStickyNavbar_mojV" id="scheduler-options">Scheduler Options<a class="hash-link" href="#scheduler-options" title="Direct link to heading">​</a></h5><p>FIFO、Capacity、Fair</p><p><img alt="Cluster utilization over time when running a large job and a small job under the FIFO Scheduler (i), Capacity Scheduler (ii), and Fair Scheduler (iii)" src="/assets/images/hddg_0403-91bd7d465f01d39e5212e61ed800e430.png" width="382" height="1000"></p><p>Capacity scheduler的资源是在配置里定义的</p><p>Fair Scheduler：用户A 和用户B 如下图</p><p><img alt="Fair sharing between user queues" src="/assets/images/hddg_0404-653cd8c49bb839c8537197fb5994eed1.png" width="755" height="714"></p><p>资源在用户之间也是Fair shared。</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="dominant-resource-fairness">Dominant Resource Fairness<a class="hash-link" href="#dominant-resource-fairness" title="Direct link to heading">​</a></h5><p>这个很有意思，是针对任务使用异构资源的算法。</p><p>假如集群有100CPU 10T 内存，A任务需求 2CPU 300G内存，B任务需求6CPU 100G内存</p><p>它是按照资源需求占集群总资源的百分比算的，A占2% 3%,B占6% 1%</p><p>所以B的Container数量会比A少一半，来达到平衡</p><p>默认DRF是关闭的。</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="data-integrity">Data Integrity<a class="hash-link" href="#data-integrity" title="Direct link to heading">​</a></h5><p>HDFS默认会在数据写入后计算checksum，然后在读取时验证。</p><p>默认每512byte就进行一次CRC-32C checksum，存一个4byte的哈希值。</p><p>Datanode 负责在数据写入之前验证checksum，然后在读取时也是一样。每个Datanode都有一个persistent log来记录verification，记录最后一次每个Block验证的时间。Client验证Block后，会回传结果给Datanode更新log。</p><p>除了在读写操作以外，DataBlockScanner还会在后台定期检查验证blocks。</p><p>当发现出错后，由于HDFS有多个备份，就可以把一个好的备份复制过来。</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="compression">Compression<a class="hash-link" href="#compression" title="Direct link to heading">​</a></h5><table><thead><tr><th>Compression format</th><th>Tool</th><th>Algorithm</th><th>Filename extension</th><th>Splittable?</th></tr></thead><tbody><tr><td>DEFLATE[<a href="https://learning.oreilly.com/library/view/hadoop-the-definitive/9781491901687/ch05.html#ftn.id585983" target="_blank" rel="noopener noreferrer">a</a>]</td><td>N/A</td><td>DEFLATE</td><td><em>.deflate</em></td><td>No</td></tr><tr><td>gzip</td><td><em>gzip</em></td><td>DEFLATE</td><td><em>.gz</em></td><td>No</td></tr><tr><td>bzip2</td><td><em>bzip2</em></td><td>bzip2</td><td><em>.bz2</em></td><td>Yes</td></tr><tr><td>LZO</td><td><em>lzop</em></td><td>LZO</td><td><em>.lzo</em></td><td>No[<a href="https://learning.oreilly.com/library/view/hadoop-the-definitive/9781491901687/ch05.html#ftn.id726357" target="_blank" rel="noopener noreferrer">b</a>]</td></tr><tr><td>LZ4</td><td>N/A</td><td>LZ4</td><td><em>.lz4</em></td><td>No</td></tr><tr><td>Snappy</td><td>N/A</td><td>Snappy</td><td><em>.snappy</em></td><td>No</td></tr></tbody></table><h5 class="anchor anchorWithStickyNavbar_mojV" id="splitting">Splitting<a class="hash-link" href="#splitting" title="Direct link to heading">​</a></h5><p>如果压缩文件大于128MB，那么就会被分成多个Block。然而，不是所有格式都支持任意区域开始解压缩。比如gzip，就必须同一个Map完成连续多个Block的读取来完成解压。</p><p>Bz2，LZO都是可以分块的，这样可以分布式地处理</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="sequencefile">SequenceFile<a class="hash-link" href="#sequencefile" title="Direct link to heading">​</a></h5><p><img alt="The internal structure of a sequence file with no compression and with record compression" src="/assets/images/hddg_0502-a0e1ef72e84ab76bbedf95de7921eac3.png" width="1000" height="529"></p><p><img alt="The internal structure of a sequence file with block compression" src="/assets/images/hddg_0503-4f3251d4d3811eccf37528af01dbe1cb.png" width="1000" height="355"></p><h5 class="anchor anchorWithStickyNavbar_mojV" id="run-a-mapreduce-job">Run a MapReduce Job<a class="hash-link" href="#run-a-mapreduce-job" title="Direct link to heading">​</a></h5><p><img alt="How Hadoop runs a MapReduce job" src="/assets/images/hddg_0701-2fdcca932e60f88b5f572fb72f9f5153.png" width="1000" height="988"></p><h5 class="anchor anchorWithStickyNavbar_mojV" id="streaming">Streaming<a class="hash-link" href="#streaming" title="Direct link to heading">​</a></h5><p><img alt="The relationship of the Streaming executable to the node manager and the task container" src="/assets/images/hddg_0702-b3791110376be07016d6e7fd620bada8.png" width="448" height="1000"></p><h4 class="anchor anchorWithStickyNavbar_mojV" id="shuffle-and-sort">Shuffle and Sort<a class="hash-link" href="#shuffle-and-sort" title="Direct link to heading">​</a></h4><p><img alt="Shuffle and sort in MapReduce" src="/assets/images/hddg_0704-07f10a071f0f4f7892b3605621ca724d.png" width="1000" height="447"></p><h5 class="anchor anchorWithStickyNavbar_mojV" id="map-side">Map Side<a class="hash-link" href="#map-side" title="Direct link to heading">​</a></h5><p>每个Map都有一个memory buffer，默认是100MB。</p><p>Map会将输出写到这个buffer里，每当buffer写满后，就会触发spill，创建一个磁盘上的spill文件然后清空buffer。这个buffer是分区(partitioned)的，对应下游的reducer。然后对每个partition，后台会有一个进程对其中的key进行sort，然后再对sort运行一边combiner。</p><p>多个Spill文件会被合成为一个分块的有序文件。如果合成前spill 文件大于3个，combiner会再次运行，否则不会运行。在此过程中，数据也会被压缩。</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="reduce-side">Reduce Side<a class="hash-link" href="#reduce-side" title="Direct link to heading">​</a></h5><p>当Map 任务完成后，会向Application Master发送消息，然后就知道了Map output和host的关系。只有当Application Master向map host发送消息要求删除结果后，结果才会被删除。</p><p>Copy phase：从map output复制结果，后台有多个copier threads，默认是5个。</p><p>当copies被复制到磁盘上，就会开始merge。这个过程由merge factor控制，如果默认值10，收到了50个结果，就要merge 5次后形成5个文件。最后这5个文件不会被merge，而是直接送到reducer</p><p><img alt="Efficiently merging 40 file segments with a merge factor of 10" src="/assets/images/hddg_0705-7df5dacfb8bd9b80e405a767ecaad8a3.png" width="704" height="1000"></p><p>如果是40个文件：第一次4个，然后10、10、10 这四次产生的4个文件和最后剩下的6个合并成为一次merge。</p><p>这样做是为了最小化io次数。</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="speculative-execution">Speculative Execution<a class="hash-link" href="#speculative-execution" title="Direct link to heading">​</a></h5><p>如果hadoop在运行过程中发现哪个task比预期执行地慢，就会启动一个同样内容的backup 任务。谁先完成，另一个都会被kill掉。这部分只会占很小一部分，显著慢于其他任务时才会触发。</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="filesystem-image-and-edit-log">Filesystem Image and Edit log<a class="hash-link" href="#filesystem-image-and-edit-log" title="Direct link to heading">​</a></h5><p>当客户端发起写请求，这个操作会被记录在edit log中。namenode在内存中也会有一个metadata的数据结构，在edit log修改后更新。这个内存中的metadata会用来响应读请求。</p><p>Edit log事实上是很多文件，如<em>edits_inprogress_0000000000000000020</em> 后缀是transaction ID，前缀是edit。</p><p>每次只有一个文件打开可以写入，在事务完成后flush，sync。</p><p>fsimage是 metadata的完全checkpoint，通常很大，GB级别。内容包含文件系统中所有文件夹和文件的inode，代表metadata。fsimage<strong>不包含</strong>block在哪个datanode上存储。</p><p>为了不让Edit log过多，只能另起一个namenode，定时地取最新的fsimage和edit log，然后合并成最新的fsimage回传给namenode，这样edit log就不会太多。</p><p><img alt="The checkpointing process" src="/assets/images/hddg_1101-ea910422f7350ad26adec87e726ddc0e.png" width="921" height="1000"></p><h5 class="anchor anchorWithStickyNavbar_mojV" id="safe-mode">Safe mode<a class="hash-link" href="#safe-mode" title="Direct link to heading">​</a></h5><p>只对client提供文件系统的Read-only view</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="balancer">Balancer<a class="hash-link" href="#balancer" title="Direct link to heading">​</a></h5><p>把空间使用率最高的node上一部分block移动到最低的node</p><p><code>start-balancer.sh</code></p><h4 class="anchor anchorWithStickyNavbar_mojV" id="安装">安装<a class="hash-link" href="#安装" title="Direct link to heading">​</a></h4><p><code>brew install hadoop</code></p><p>注意安装的位置</p><p>本书的代码可以在github上找到，repo owner就是书的作者</p><p><a href="https://github.com/tomwhite/hadoop-book" target="_blank" rel="noopener noreferrer">tomwhite/hadoop-book: Example source code accompanying O&#x27;Reilly&#x27;s &quot;Hadoop: The Definitive Guide&quot; by Tom White (github.com)</a></p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">hadoop-book git:(master) ✗ hadoop jar /opt/homebrew/Cellar/hadoop/3.3.3/libexec/share/hadoop/tools/lib/hadoop-streaming-*.jar \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -input input/ncdc/sample.txt \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -output output \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -mapper ch02-mr-intro/src/main/python/max_temperature_map.py \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -reducer ch02-mr-intro/src/main/python/max_temperature_reduce.py</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p><a href="https://towardsdatascience.com/installing-hadoop-on-a-mac-ec01c67b003c" target="_blank" rel="noopener noreferrer">Installing Hadoop on a Mac. The only guide you will ever need! | by Siphu Langeni, MS | Towards Data Science</a></p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">$ open core-site.xml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;configuration&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;property&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;/property&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/configuration&gt;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">$ open hdfs-site.xml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;configuration&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;property&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;name&gt;dfs.replication&lt;/name&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;value&gt;1&lt;/value&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;/property&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/configuration&gt;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">$ open mapred-site.xml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;configuration&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;property&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;value&gt;yarn&lt;/value&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;/property&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;property&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;name&gt;mapreduce.application.classpath&lt;/name&gt;   &lt;value&gt;/opt/homebrew/Cellar/hadoop/3.3.3/libexec/share/hadoop/mapreduce/*:/opt/homebrew/Cellar/hadoop/3.3.3/libexec/share/hadoop/mapreduce/lib/*&lt;/value&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;/property&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/configuration&gt;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">open yarn-site.xml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;configuration&gt; </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;property&gt; </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;value&gt;mapreduce_shuffle&lt;/value&gt; </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;/property&gt; </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;property&gt; </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt; &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt; </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;/property&gt; </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;/configuration&gt;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>Ssh 本地可以跑通，在设置里打开权限</p><p><img alt="image-20220822092415975" src="/assets/images/image-20220822092415975-543a7f23bdc85f3bcfba7f50e627bf61.png" width="1318" height="1062"></p><h4 class="anchor anchorWithStickyNavbar_mojV" id="相关项目深坑">相关项目（深坑）<a class="hash-link" href="#相关项目深坑" title="Direct link to heading">​</a></h4><h5 class="anchor anchorWithStickyNavbar_mojV" id="avro">Avro<a class="hash-link" href="#avro" title="Direct link to heading">​</a></h5><p>数据序列化系统</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="parquet">Parquet<a class="hash-link" href="#parquet" title="Direct link to heading">​</a></h5><p>列存储格式</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="flume">Flume<a class="hash-link" href="#flume" title="Direct link to heading">​</a></h5><p>数据Ingestion</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="sqoop">Sqoop<a class="hash-link" href="#sqoop" title="Direct link to heading">​</a></h5><p>从关系型数据库提取数据</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="pig">Pig<a class="hash-link" href="#pig" title="Direct link to heading">​</a></h5><p>处理大型数据集</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="hive">Hive<a class="hash-link" href="#hive" title="Direct link to heading">​</a></h5><p>Data warehouse</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="crunch">Crunch<a class="hash-link" href="#crunch" title="Direct link to heading">​</a></h5><p>Map Reduce高级API</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="spark">Spark<a class="hash-link" href="#spark" title="Direct link to heading">​</a></h5><p>大数据处理引擎</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="hbase">HBase<a class="hash-link" href="#hbase" title="Direct link to heading">​</a></h5><p>Big table</p><p>这些有空再更新吧……</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/big-data/hadoop.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_dcUD" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_foO9"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/docs/ai/interpretable_ai"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">interpretable_ai</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/docs/big-data/kafka"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">kafka</div></a></div></nav></div></div><div class="col col--3"><div class="tableOfContents_cNA8 thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#hadoop" class="table-of-contents__link toc-highlight">Hadoop</a></li><li><a href="#hadoop-distributed-filesystem-hdfs" class="table-of-contents__link toc-highlight">Hadoop Distributed Filesystem (HDFS)</a></li><li><a href="#yarn-yet-another-resource-negotiator" class="table-of-contents__link toc-highlight">YARN (Yet Another Resource Negotiator)</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2022 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.8c487385.js"></script>
<script src="/assets/js/main.036a9873.js"></script>
</body>
</html>